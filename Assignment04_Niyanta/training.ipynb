{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e129fcd",
   "metadata": {},
   "source": [
    "# Assignment 04 Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0712065",
   "metadata": {},
   "source": [
    "Exercise 1: Using RNNs/LSTMs to generate Python code\n",
    "\n",
    "Using TensorFlow, design and develop an RNN/LSTM model for generating fake Python code (functions, etc.). \n",
    "Use any of the Python repos freely available. Analyze the accuracy of the model and point out some of the pitfalls. \n",
    "You may refer to the article below for the LSTM net architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebcb9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb6f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample python file\n",
    "raw_text = open(\"./sample.py\", 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "470f69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cb913fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  19130\n",
      "Total Vocab:  62\n"
     ]
    }
   ],
   "source": [
    "# summarizing the dataset.\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters in the file: \", n_chars)\n",
    "print(\"Total Vocab in the file: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f534bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  19110\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 20\n",
    "dataX = []\n",
    "dataY = []\n",
    "#pattern\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    " seq_in = raw_text[i:i + seq_length]\n",
    " seq_out = raw_text[i + seq_length]\n",
    " dataX.append([char_to_int[char] for char in seq_in])\n",
    " dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132fad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "X = X / float(n_vocab)\n",
    "y = to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdbdac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelling\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3e1252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 2.9163\n",
      "Epoch 1: loss improved from inf to 2.91630, saving model to lstm_weighs-01-2.9163.hdf5\n",
      "598/598 [==============================] - 66s 99ms/step - loss: 2.9163\n",
      "Epoch 2/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 2.7559\n",
      "Epoch 2: loss improved from 2.91630 to 2.75591, saving model to lstm_weighs-02-2.7559.hdf5\n",
      "598/598 [==============================] - 57s 96ms/step - loss: 2.7559\n",
      "Epoch 3/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 2.6713\n",
      "Epoch 3: loss improved from 2.75591 to 2.67131, saving model to lstm_weighs-03-2.6713.hdf5\n",
      "598/598 [==============================] - 62s 104ms/step - loss: 2.6713\n",
      "Epoch 4/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 2.5596\n",
      "Epoch 4: loss improved from 2.67131 to 2.55957, saving model to lstm_weighs-04-2.5596.hdf5\n",
      "598/598 [==============================] - 66s 110ms/step - loss: 2.5596\n",
      "Epoch 5/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 2.4316\n",
      "Epoch 5: loss improved from 2.55957 to 2.43163, saving model to lstm_weighs-05-2.4316.hdf5\n",
      "598/598 [==============================] - 64s 106ms/step - loss: 2.4316\n",
      "Epoch 6/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 2.2982\n",
      "Epoch 6: loss improved from 2.43163 to 2.29817, saving model to lstm_weighs-06-2.2982.hdf5\n",
      "598/598 [==============================] - 64s 107ms/step - loss: 2.2982\n",
      "Epoch 7/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 2.1690\n",
      "Epoch 7: loss improved from 2.29817 to 2.16905, saving model to lstm_weighs-07-2.1690.hdf5\n",
      "598/598 [==============================] - 64s 107ms/step - loss: 2.1690\n",
      "Epoch 8/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 2.0377\n",
      "Epoch 8: loss improved from 2.16905 to 2.03774, saving model to lstm_weighs-08-2.0377.hdf5\n",
      "598/598 [==============================] - 78s 131ms/step - loss: 2.0377\n",
      "Epoch 9/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 1.9126\n",
      "Epoch 9: loss improved from 2.03774 to 1.91263, saving model to lstm_weighs-09-1.9126.hdf5\n",
      "598/598 [==============================] - 70s 117ms/step - loss: 1.9126\n",
      "Epoch 10/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 1.7926\n",
      "Epoch 10: loss improved from 1.91263 to 1.79259, saving model to lstm_weighs-10-1.7926.hdf5\n",
      "598/598 [==============================] - 70s 118ms/step - loss: 1.7926\n",
      "Epoch 11/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 1.6908\n",
      "Epoch 11: loss improved from 1.79259 to 1.69076, saving model to lstm_weighs-11-1.6908.hdf5\n",
      "598/598 [==============================] - 67s 112ms/step - loss: 1.6908\n",
      "Epoch 12/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 1.5883\n",
      "Epoch 12: loss improved from 1.69076 to 1.58834, saving model to lstm_weighs-12-1.5883.hdf5\n",
      "598/598 [==============================] - 71s 118ms/step - loss: 1.5883\n",
      "Epoch 13/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 1.5060\n",
      "Epoch 13: loss improved from 1.58834 to 1.50600, saving model to lstm_weighs-13-1.5060.hdf5\n",
      "598/598 [==============================] - 72s 120ms/step - loss: 1.5060\n",
      "Epoch 14/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 1.4154\n",
      "Epoch 14: loss improved from 1.50600 to 1.41536, saving model to lstm_weighs-14-1.4154.hdf5\n",
      "598/598 [==============================] - 71s 119ms/step - loss: 1.4154\n",
      "Epoch 15/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 1.3358\n",
      "Epoch 15: loss improved from 1.41536 to 1.33576, saving model to lstm_weighs-15-1.3358.hdf5\n",
      "598/598 [==============================] - 68s 114ms/step - loss: 1.3358\n",
      "Epoch 16/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 1.2609\n",
      "Epoch 16: loss improved from 1.33576 to 1.26094, saving model to lstm_weighs-16-1.2609.hdf5\n",
      "598/598 [==============================] - 69s 115ms/step - loss: 1.2609\n",
      "Epoch 17/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 1.1893\n",
      "Epoch 17: loss improved from 1.26094 to 1.18930, saving model to lstm_weighs-17-1.1893.hdf5\n",
      "598/598 [==============================] - 69s 115ms/step - loss: 1.1893\n",
      "Epoch 18/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 1.1301\n",
      "Epoch 18: loss improved from 1.18930 to 1.13009, saving model to lstm_weighs-18-1.1301.hdf5\n",
      "598/598 [==============================] - 68s 114ms/step - loss: 1.1301\n",
      "Epoch 19/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 1.0648\n",
      "Epoch 19: loss improved from 1.13009 to 1.06479, saving model to lstm_weighs-19-1.0648.hdf5\n",
      "598/598 [==============================] - 69s 115ms/step - loss: 1.0648\n",
      "Epoch 20/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 1.0131\n",
      "Epoch 20: loss improved from 1.06479 to 1.01310, saving model to lstm_weighs-20-1.0131.hdf5\n",
      "598/598 [==============================] - 67s 113ms/step - loss: 1.0131\n",
      "Epoch 21/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.9527\n",
      "Epoch 21: loss improved from 1.01310 to 0.95268, saving model to lstm_weighs-21-0.9527.hdf5\n",
      "598/598 [==============================] - 69s 115ms/step - loss: 0.9527\n",
      "Epoch 22/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.9044\n",
      "Epoch 22: loss improved from 0.95268 to 0.90436, saving model to lstm_weighs-22-0.9044.hdf5\n",
      "598/598 [==============================] - 69s 115ms/step - loss: 0.9044\n",
      "Epoch 23/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.8615\n",
      "Epoch 23: loss improved from 0.90436 to 0.86152, saving model to lstm_weighs-23-0.8615.hdf5\n",
      "598/598 [==============================] - 68s 114ms/step - loss: 0.8615\n",
      "Epoch 24/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.8044\n",
      "Epoch 24: loss improved from 0.86152 to 0.80437, saving model to lstm_weighs-24-0.8044.hdf5\n",
      "598/598 [==============================] - 68s 114ms/step - loss: 0.8044\n",
      "Epoch 25/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.7697\n",
      "Epoch 25: loss improved from 0.80437 to 0.76966, saving model to lstm_weighs-25-0.7697.hdf5\n",
      "598/598 [==============================] - 73s 121ms/step - loss: 0.7697\n",
      "Epoch 26/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.7303\n",
      "Epoch 26: loss improved from 0.76966 to 0.73029, saving model to lstm_weighs-26-0.7303.hdf5\n",
      "598/598 [==============================] - 68s 113ms/step - loss: 0.7303\n",
      "Epoch 27/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.7012\n",
      "Epoch 27: loss improved from 0.73029 to 0.70123, saving model to lstm_weighs-27-0.7012.hdf5\n",
      "598/598 [==============================] - 67s 113ms/step - loss: 0.7012\n",
      "Epoch 28/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.6576\n",
      "Epoch 28: loss improved from 0.70123 to 0.65759, saving model to lstm_weighs-28-0.6576.hdf5\n",
      "598/598 [==============================] - 67s 112ms/step - loss: 0.6576\n",
      "Epoch 29/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.6380\n",
      "Epoch 29: loss improved from 0.65759 to 0.63798, saving model to lstm_weighs-29-0.6380.hdf5\n",
      "598/598 [==============================] - 70s 117ms/step - loss: 0.6380\n",
      "Epoch 30/50\n",
      "597/598 [============================>.] - ETA: 1s - loss: 0.5973\n",
      "Epoch 30: loss improved from 0.63798 to 0.59714, saving model to lstm_weighs-30-0.5971.hdf5\n",
      "598/598 [==============================] - 640s 1s/step - loss: 0.5971\n",
      "Epoch 31/50\n",
      "597/598 [============================>.] - ETA: 0s - loss: 0.5692\n",
      "Epoch 31: loss improved from 0.59714 to 0.56981, saving model to lstm_weighs-31-0.5698.hdf5\n",
      "598/598 [==============================] - 57s 96ms/step - loss: 0.5698\n",
      "Epoch 32/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.5483\n",
      "Epoch 32: loss improved from 0.56981 to 0.54827, saving model to lstm_weighs-32-0.5483.hdf5\n",
      "598/598 [==============================] - 59s 99ms/step - loss: 0.5483\n",
      "Epoch 33/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.5207\n",
      "Epoch 33: loss improved from 0.54827 to 0.52068, saving model to lstm_weighs-33-0.5207.hdf5\n",
      "598/598 [==============================] - 61s 102ms/step - loss: 0.5207\n",
      "Epoch 34/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.4984\n",
      "Epoch 34: loss improved from 0.52068 to 0.49841, saving model to lstm_weighs-34-0.4984.hdf5\n",
      "598/598 [==============================] - 67s 112ms/step - loss: 0.4984\n",
      "Epoch 35/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.4754\n",
      "Epoch 35: loss improved from 0.49841 to 0.47540, saving model to lstm_weighs-35-0.4754.hdf5\n",
      "598/598 [==============================] - 161s 270ms/step - loss: 0.4754\n",
      "Epoch 36/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.4786\n",
      "Epoch 36: loss did not improve from 0.47540\n",
      "598/598 [==============================] - 60s 100ms/step - loss: 0.4786\n",
      "Epoch 37/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.4510\n",
      "Epoch 37: loss improved from 0.47540 to 0.45102, saving model to lstm_weighs-37-0.4510.hdf5\n",
      "598/598 [==============================] - 60s 100ms/step - loss: 0.4510\n",
      "Epoch 38/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.4385\n",
      "Epoch 38: loss improved from 0.45102 to 0.43852, saving model to lstm_weighs-38-0.4385.hdf5\n",
      "598/598 [==============================] - 83s 139ms/step - loss: 0.4385\n",
      "Epoch 39/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.4241\n",
      "Epoch 39: loss improved from 0.43852 to 0.42408, saving model to lstm_weighs-39-0.4241.hdf5\n",
      "598/598 [==============================] - 1145s 2s/step - loss: 0.4241\n",
      "Epoch 40/50\n",
      "597/598 [============================>.] - ETA: 0s - loss: 0.4146\n",
      "Epoch 40: loss improved from 0.42408 to 0.41470, saving model to lstm_weighs-40-0.4147.hdf5\n",
      "598/598 [==============================] - 58s 97ms/step - loss: 0.4147\n",
      "Epoch 41/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.3990\n",
      "Epoch 41: loss improved from 0.41470 to 0.39899, saving model to lstm_weighs-41-0.3990.hdf5\n",
      "598/598 [==============================] - 57s 95ms/step - loss: 0.3990\n",
      "Epoch 42/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.3927\n",
      "Epoch 42: loss improved from 0.39899 to 0.39273, saving model to lstm_weighs-42-0.3927.hdf5\n",
      "598/598 [==============================] - 58s 97ms/step - loss: 0.3927\n",
      "Epoch 43/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.3848\n",
      "Epoch 43: loss improved from 0.39273 to 0.38479, saving model to lstm_weighs-43-0.3848.hdf5\n",
      "598/598 [==============================] - 68s 113ms/step - loss: 0.3848\n",
      "Epoch 44/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.3750\n",
      "Epoch 44: loss improved from 0.38479 to 0.37503, saving model to lstm_weighs-44-0.3750.hdf5\n",
      "598/598 [==============================] - 67s 112ms/step - loss: 0.3750\n",
      "Epoch 45/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.3451\n",
      "Epoch 45: loss improved from 0.37503 to 0.34509, saving model to lstm_weighs-45-0.3451.hdf5\n",
      "598/598 [==============================] - 70s 118ms/step - loss: 0.3451\n",
      "Epoch 46/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.3491\n",
      "Epoch 46: loss did not improve from 0.34509\n",
      "598/598 [==============================] - 64s 107ms/step - loss: 0.3491\n",
      "Epoch 47/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.3343\n",
      "Epoch 47: loss improved from 0.34509 to 0.33428, saving model to lstm_weighs-47-0.3343.hdf5\n",
      "598/598 [==============================] - 77s 129ms/step - loss: 0.3343\n",
      "Epoch 48/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.3405\n",
      "Epoch 48: loss did not improve from 0.33428\n",
      "598/598 [==============================] - 66s 111ms/step - loss: 0.3405\n",
      "Epoch 49/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.3277\n",
      "Epoch 49: loss improved from 0.33428 to 0.32774, saving model to lstm_weighs-49-0.3277.hdf5\n",
      "598/598 [==============================] - 66s 111ms/step - loss: 0.3277\n",
      "Epoch 50/50\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.3219\n",
      "Epoch 50: loss improved from 0.32774 to 0.32187, saving model to lstm_weighs-50-0.3219.hdf5\n",
      "598/598 [==============================] - 65s 109ms/step - loss: 0.3219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14b232bb310>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"lstm_weighs-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X, y, epochs=50, batch_size=32, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca707f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33a6583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a03920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
